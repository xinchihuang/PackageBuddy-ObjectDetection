{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess_config = tf.ConfigProto()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "COCO_DATA = '../data/coco'\n",
    "MASK_RCNN_MODEL_PATH = '../lib/Mask_RCNN/'\n",
    "SIAMESE_MASK_RCNN_PATH = '../'\n",
    "\n",
    "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
    "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
    "if SIAMESE_MASK_RCNN_PATH not in sys.path:\n",
    "    sys.path.append(SIAMESE_MASK_RCNN_PATH)\n",
    "    \n",
    "from samples.coco import coco\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "    \n",
    "from lib import utils as siamese_utils\n",
    "from lib import model as siamese_model\n",
    "from lib import config as siamese_config\n",
    "from collections import OrderedDict\n",
    "    \n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import imgaug\n",
    "import pickle\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 4\n",
    "    IMAGES_PER_GPU = 3\n",
    "    NUM_CLASSES = 80 + 1\n",
    "    NAME = 'parallel_mrcnn_coco'\n",
    "    EXPERIMENT = 'full'\n",
    "    CHECKPOINT_DIR = '../checkpoints/'\n",
    "    # Reduced image sizes\n",
    "    TARGET_MAX_DIM = 192\n",
    "    TARGET_MIN_DIM = 150\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Reduce model size\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
    "    FPN_FEATUREMAPS = 256\n",
    "    TOP_DOWN_PYRAMID_SIZE = 256\n",
    "    # Reduce number of rois at all stages\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    # Adapt NMS Threshold\n",
    "    DETECTION_NMS_THRESHOLD = 0.5\n",
    "    # Adapt loss weights\n",
    "    LOSS_WEIGHTS = {'rpn_class_loss': 2.0, \n",
    "                    'rpn_bbox_loss': 0.1, \n",
    "                    'mrcnn_class_loss': 2.0, \n",
    "                    'mrcnn_bbox_loss': 0.5, \n",
    "                    'mrcnn_mask_loss': 1.0}\n",
    "    \n",
    "    STEPS_PER_EPOCH = 50\n",
    "    VALIDATION_STEPS = 1\n",
    "    \n",
    "config = TrainConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(ROOT_DIR, \"{}_{}\".format(config.NAME.lower(), config.EXPERIMENT.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO/train dataset\n",
    "coco_train = siamese_utils.IndexedCocoDataset()\n",
    "coco_train.load_coco(COCO_DATA, subset=\"train\", subsubset=\"train\", year=\"2017\")\n",
    "coco_train.prepare()\n",
    "coco_train.build_indices()\n",
    "coco_train.ACTIVE_CLASSES = np.array(range(1,81))\n",
    "\n",
    "# Load COCO/val dataset\n",
    "coco_val = siamese_utils.IndexedCocoDataset()\n",
    "coco_val.load_coco(COCO_DATA, subset=\"train\", subsubset=\"val\", year=\"2017\")\n",
    "coco_val.prepare()\n",
    "coco_val.build_indices()\n",
    "coco_val.ACTIVE_CLASSES = np.array(range(1,81))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.initializers as KI\n",
    "import keras.engine as KE\n",
    "import keras.models as KM\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpn_classifier_graph(rois, feature_maps, image_meta,\n",
    "                         pool_size, num_classes, train_bn=True, fc_layers_size=1024):\n",
    "    \"\"\"Builds the computation graph of the feature pyramid network classifier\n",
    "    and regressor heads.\n",
    "    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized\n",
    "          coordinates.\n",
    "    feature_maps: List of feature maps from diffent layers of the pyramid,\n",
    "                  [P2, P3, P4, P5]. Each has a different resolution.\n",
    "    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    pool_size: The width of the square feature map generated from ROI Pooling.\n",
    "    num_classes: number of classes, which determines the depth of the results\n",
    "    train_bn: Boolean. Train or freeze Batch Norm layres\n",
    "    Returns:\n",
    "        logits: [N, NUM_CLASSES] classifier logits (before softmax)\n",
    "        probs: [N, NUM_CLASSES] classifier probabilities\n",
    "        bbox_deltas: [N, (dy, dx, log(dh), log(dw))] Deltas to apply to\n",
    "                     proposal boxes\n",
    "    \"\"\"\n",
    "    # ROI Pooling\n",
    "    # Shape: [batch, num_boxes, pool_height, pool_width, channels]\n",
    "    x = modellib.PyramidROIAlign([pool_size, pool_size],\n",
    "                        name=\"roi_align_classifier\")([rois, image_meta] + feature_maps)\n",
    "    # Two 1024 FC layers (implemented with Conv2D for consistency)\n",
    "    x = KL.TimeDistributed(KL.Conv2D(fc_layers_size, (pool_size, pool_size), padding=\"valid\"),\n",
    "                           name=\"mrcnn_class_conv1\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(), name='mrcnn_class_bn1')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    x = KL.TimeDistributed(KL.Conv2D(fc_layers_size, (1, 1)),\n",
    "                           name=\"mrcnn_class_conv2\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(), name='mrcnn_class_bn2')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "\n",
    "    shared = KL.Lambda(lambda x: K.squeeze(K.squeeze(x, 3), 2),\n",
    "                       name=\"pool_squeeze\")(x)\n",
    "\n",
    "    # Classifier head\n",
    "    mrcnn_class_logits = KL.TimeDistributed(KL.Dense(num_classes),\n",
    "                                            name='mrcnn_class_logits')(shared)\n",
    "    mrcnn_probs = KL.TimeDistributed(KL.Activation(\"softmax\"),\n",
    "                                     name=\"mrcnn_class\")(mrcnn_class_logits)\n",
    "\n",
    "    # BBox head\n",
    "    # [batch, boxes, num_classes * (dy, dx, log(dh), log(dw))]\n",
    "    x = KL.TimeDistributed(KL.Dense(4, activation='linear'),\n",
    "                           name='mrcnn_bbox_fc')(shared)\n",
    "    # Reshape to [batch, boxes, num_classes, (dy, dx, log(dh), log(dw))]\n",
    "    s = K.int_shape(x)\n",
    "    x = KL.Reshape((s[1],1, 4), name=\"mrcnn_bbox\")(x)\n",
    "    mrcnn_bbox = x\n",
    "\n",
    "    return mrcnn_class_logits, mrcnn_probs, mrcnn_bbox\n",
    "\n",
    "modellib.fpn_classifier_graph = fpn_classifier_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrcnn_class_loss_graph(target_class_ids, pred_class_logits, active_class_ids):\n",
    "    \"\"\"Loss for the classifier head of Mask RCNN.\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs. Uses zero\n",
    "        padding to fill in the array.\n",
    "    pred_class_logits: [batch, num_rois, num_classes]\n",
    "    active_class_ids: [batch, num_classes]. Has a value of 1 for\n",
    "        classes that are in the dataset of the image, and 0\n",
    "        for classes that are not in the dataset.\n",
    "    \"\"\"\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    # Computer loss mean:\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "modellib.mrcnn_class_loss_graph = mrcnn_class_loss_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):\n",
    "    \"\"\"Loss for Mask R-CNN bounding box refinement.\n",
    "\n",
    "    target_bbox: [batch, num_rois, (dy, dx, log(dh), log(dw))]\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs.\n",
    "    pred_bbox: [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]\n",
    "    \"\"\"\n",
    "    # Reshape to merge batch and roi dimensions for simplicity.\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    target_bbox = K.reshape(target_bbox, (-1, 4))\n",
    "    pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))\n",
    "\n",
    "    # Only positive ROIs contribute to the loss. And only\n",
    "    # the right class_id of each ROI. Get their indicies.\n",
    "    positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "    #positive_roi_class_ids = tf.cast(\n",
    "    #    tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "    #indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "    # Gather the deltas (predicted and true) that contribute to loss\n",
    "    target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "    pred_bbox = tf.gather(pred_bbox, positive_roi_ix)\n",
    "\n",
    "    # Smooth-L1 Loss\n",
    "    loss = K.switch(tf.size(target_bbox) > 0,\n",
    "                    modellib.smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "modellib.mrcnn_bbox_loss_graph = mrcnn_bbox_loss_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fpn_mask_graph(rois, feature_maps, image_meta,\n",
    "                         pool_size, num_classes, train_bn=True):\n",
    "    \"\"\"Builds the computation graph of the mask head of Feature Pyramid Network.\n",
    "    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized\n",
    "          coordinates.\n",
    "    feature_maps: List of feature maps from diffent layers of the pyramid,\n",
    "                  [P2, P3, P4, P5]. Each has a different resolution.\n",
    "    image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    pool_size: The width of the square feature map generated from ROI Pooling.\n",
    "    num_classes: number of classes, which determines the depth of the results\n",
    "    train_bn: Boolean. Train or freeze Batch Norm layres\n",
    "    Returns: Masks [batch, roi_count, height, width, num_classes]\n",
    "    \"\"\"\n",
    "    # ROI Pooling\n",
    "    # Shape: [batch, boxes, pool_height, pool_width, channels]\n",
    "    x = modellib.PyramidROIAlign([pool_size, pool_size],\n",
    "                        name=\"roi_align_mask\")([rois, image_meta] + feature_maps)\n",
    "\n",
    "    # Conv layers\n",
    "    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding=\"same\"),\n",
    "                           name=\"mrcnn_mask_conv1\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(),\n",
    "                           name='mrcnn_mask_bn1')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "\n",
    "    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding=\"same\"),\n",
    "                           name=\"mrcnn_mask_conv2\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(),\n",
    "                           name='mrcnn_mask_bn2')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "\n",
    "    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding=\"same\"),\n",
    "                           name=\"mrcnn_mask_conv3\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(),\n",
    "                           name='mrcnn_mask_bn3')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "\n",
    "    x = KL.TimeDistributed(KL.Conv2D(256, (3, 3), padding=\"same\"),\n",
    "                           name=\"mrcnn_mask_conv4\")(x)\n",
    "    x = KL.TimeDistributed(modellib.BatchNorm(),\n",
    "                           name='mrcnn_mask_bn4')(x, training=train_bn)\n",
    "    x = KL.Activation('relu')(x)\n",
    "\n",
    "    x = KL.TimeDistributed(KL.Conv2DTranspose(256, (2, 2), strides=2, activation=\"relu\"),\n",
    "                           name=\"mrcnn_mask_deconv\")(x)\n",
    "    x = KL.TimeDistributed(KL.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\"),\n",
    "                           name=\"mrcnn_mask\")(x)\n",
    "    return x\n",
    "\n",
    "modellib.build_fpn_mask_graph = build_fpn_mask_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrcnn_mask_loss_graph(target_masks, target_class_ids, pred_masks):\n",
    "    \"\"\"Mask binary cross-entropy loss for the masks head.\n",
    "    target_masks: [batch, num_rois, height, width].\n",
    "        A float32 tensor of values 0 or 1. Uses zero padding to fill array.\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs. Zero padded.\n",
    "    pred_masks: [batch, proposals, height, width, num_classes] float32 tensor\n",
    "                with values from 0 to 1.\n",
    "    \"\"\"\n",
    "    # Reshape for simplicity. Merge first two dimensions into one.\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    pred_masks = K.squeeze(pred_masks, axis=-1)\n",
    "    mask_shape = tf.shape(target_masks)\n",
    "    target_masks = K.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\n",
    "    pred_shape = tf.shape(pred_masks)\n",
    "    pred_masks = K.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3]))\n",
    "#     # Permute predicted masks to [N, num_classes, height, width]\n",
    "#     pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\n",
    "\n",
    "    # Only positive ROIs contribute to the loss. And only\n",
    "    # the class specific mask of each ROI.\n",
    "    positive_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "#     positive_class_ids = tf.cast(\n",
    "#         tf.gather(target_class_ids, positive_ix), tf.int64)\n",
    "#     indices = tf.stack([positive_ix, positive_ix], axis=1)\n",
    "\n",
    "    # Gather the masks (predicted and true) that contribute to loss\n",
    "    y_true = tf.gather(target_masks, positive_ix)\n",
    "    y_pred = tf.gather(pred_masks, positive_ix)\n",
    "\n",
    "    # Compute binary cross entropy. If no positive ROIs, then return 0.\n",
    "    # shape: [batch, roi, num_classes]\n",
    "    loss = K.switch(tf.size(y_true) > 0,\n",
    "                    K.binary_crossentropy(target=y_true, output=y_pred),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "modellib.mrcnn_mask_loss_graph = mrcnn_mask_loss_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRCNN(modellib.MaskRCNN):\n",
    "    \n",
    "    def set_log_dir(self, model_path=None):\n",
    "        \"\"\"Sets the model log directory and epoch counter.\n",
    "        model_path: If None, or a format different from what this code uses\n",
    "            then set a new log directory and start epochs from 0. Otherwise,\n",
    "            extract the log directory and the epoch counter from the file\n",
    "            name.\n",
    "        \"\"\"\n",
    "        # Set date and epoch counter as if starting a new model\n",
    "        self.epoch = 0\n",
    "        now = datetime.datetime.now()\n",
    "\n",
    "#         # If we have a model path with date and epochs use them\n",
    "#         if model_path:\n",
    "#             # Continue from we left of. Get epoch and date from the file name\n",
    "#             # A sample model path might look like:\n",
    "#             # /path/to/logs/coco20171029T2315/mask_rcnn_coco_0001.h5\n",
    "#             regex = r\".*/[\\w-]+(\\d{4})(\\d{2})(\\d{2})T(\\d{2})(\\d{2})/mask\\_rcnn\\_[\\w-]+(\\d{4})\\.h5\"\n",
    "#             m = re.match(regex, model_path)\n",
    "#             if m:\n",
    "#                 now = datetime.datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)),\n",
    "#                                         int(m.group(4)), int(m.group(5)))\n",
    "#                 # Epoch number in file is 1-based, and in Keras code it's 0-based.\n",
    "#                 # So, adjust for that then increment by one to start from the next epoch\n",
    "#                 self.epoch = int(m.group(6)) - 1 + 1\n",
    "#                 print('Re-starting from epoch %d' % self.epoch)\n",
    "\n",
    "        # Directory for training logs\n",
    "        self.log_dir = os.path.join(self.model_dir, \n",
    "                                    \"{}_{}\".format(self.config.NAME.lower(), \n",
    "                                                   self.config.EXPERIMENT.lower()))\n",
    "\n",
    "        # Create log_dir if not exists\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "\n",
    "        # Path to save after each epoch. Include placeholders that get filled by Keras.\n",
    "        self.checkpoint_path = os.path.join(self.log_dir, \"mrcnn_*epoch*.h5\")\n",
    "        self.checkpoint_path = self.checkpoint_path.replace(\"*epoch*\", \"{epoch:04d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schedule = OrderedDict()\n",
    "train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "train_schedule[240] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
    "train_schedule[320] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights trained on Imagenet\n",
    "try: \n",
    "    os.path.exists(os.path.join(model.log_dir, \"mrcnn_0001.h5\"))\n",
    "    list_of_files = glob.glob(os.path.join(model.log_dir,'*.h5')) # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "    epoch_index = int(latest_file[-7:-3])\n",
    "    print('loading', latest_file, '...')\n",
    "\n",
    "    # load weights            \n",
    "    model.load_weights(latest_file, by_name=True)\n",
    "    model.epoch = epoch_index\n",
    "except:\n",
    "    print('initializing from imagenet weights ...')\n",
    "    weights_file = model.get_imagenet_weights()\n",
    "    model.load_weights(weights_file, by_name=True)\n",
    "    model.set_log_dir()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, parameters in train_schedule.items():\n",
    "    print(\"\")\n",
    "    print(\"training layers {} until epoch {} with learning_rate {}\".format(parameters[\"layers\"], \n",
    "                                                                          epochs, \n",
    "                                                                          parameters[\"learning_rate\"]))\n",
    "    model.train(coco_train, coco_val, \n",
    "                learning_rate=parameters[\"learning_rate\"], \n",
    "                epochs=epochs, \n",
    "                layers=parameters[\"layers\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
